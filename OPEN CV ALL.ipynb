{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video viewer\n",
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(\"C:/Users/H/Videos/Captures/FRIENDS/Season 7/Friends.S07E01.MoviesFlix.Net (1).mkv\")\n",
    "while(cap.isOpened()):\n",
    "    ret,frame = cap.read()\n",
    "    if ret == True:\n",
    "        cv2.imshow(\"Frame\",frame)\n",
    "        if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "            break\n",
    "        else:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webcam\n",
    "import cv2, time\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "a = 0\n",
    "while True:\n",
    "    a = a+1\n",
    "    check,frame = video.read()\n",
    "\n",
    "    print(check)\n",
    "    print(frame)\n",
    "\n",
    "    cv2.imshow(\"Capturing\",frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    \n",
    "print(a)#time in milliseconds\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting into grayscale\n",
    "import cv2\n",
    "img = cv2.imread(\"C:/Users/H/Documents/utube.png\")\n",
    "imggray = cv2.cvtColor(img,cv2.COLOR_BAYER_BG2BGR_VNG)\n",
    "cv2.imshow('grayscale',imggray)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian blur\n",
    "#Edge detector(canny)\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"C:/Users/H/Documents/playlist/playdate.png\")\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "\n",
    "\n",
    "imgblur = cv2.GaussianBlur(img,(21,21),0)\n",
    "imgcanny = cv2.Canny(img,150,200)\n",
    "imgdilation = cv2.dilate(imgcanny,kernel,iterations = 1)\n",
    "#iterations decide thickness\n",
    "#kernel is size of matrices and values that should be in it\n",
    "imgerode = cv2.erode(imgdilation,kernel,iterations = 1)\n",
    "#erode is for decreasing thickness\n",
    "\n",
    "cv2.imshow('blur',imgblur)\n",
    "cv2.imshow('canny',imgcanny)\n",
    "cv2.imshow('dilation',imgdilation)\n",
    "cv2.imshow('eroded',imgerode)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing a image and cropping\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"C:/Users/H/Documents/playlist/playdate.png\")\n",
    "print(img.shape)#height,width,channelsnumber\n",
    "imgre = cv2.resize(img,(300,200))#width,height\n",
    "imgcrop = img[0:200,200:400]#height,width\n",
    "\n",
    "cv2.imshow('image',img)\n",
    "cv2.imshow('resizeimage',imgre)\n",
    "cv2.imshow('imagecrop',imgcrop)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing shapes on images\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((512,512,3),np.uint8)#image\n",
    "#print(img)\n",
    "\n",
    "#img[200:300,100:200] = 255,0,0\n",
    "\n",
    "#cv2.line(img,(0,0),(200,200),(0,255,0),3)#img,startpoint,endpoint,rgb color,thickness\n",
    "cv2.line(img,(0,0),(img.shape[1],img.shape[0]),(0,255,0),3)\n",
    "\n",
    "cv2.rectangle(img,(0,0),(250,350),(0,0,255),cv2.FILLED)#instead of thickness rectangle is filled\n",
    "cv2.circle(img,(400,50),30,(255,255,0),5)#img,centre,radius,color,thickness\n",
    "cv2.putText(img,\"HOW U DOIN?\",(300,100),cv2.FONT_HERSHEY_COMPLEX,.5,(0,150,0),2)#img,text,startpoint,font,scale,color,thickness\n",
    "\n",
    "cv2.imshow(\"image\",img)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining images\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"C:/Users/H/Documents/playlist/playdate.png\")\n",
    "\n",
    "hor = np.hstack((img,img))\n",
    "ver = np.vstack((img,img))\n",
    "cv2.imshow(\"Horizontal\",hor)\n",
    "cv2.imshow(\"vertical\",ver)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def empty(a):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Track Bars\")\n",
    "cv2.resizeWindow(\"Track Bars\",640,240)#same name as window,size\n",
    "cv2.createTrackbar(\"Hue Min\",\"Track Bars\",1,179,empty)#name,window name,currentvalue of hue,max. value of hue,func. which runs every time the trackbar is changed\n",
    "cv2.createTrackbar(\"Hue Max\",\"Track Bars\",179,179,empty)\n",
    "cv2.createTrackbar(\"Sat Min\",\"Track Bars\",32,255,empty)\n",
    "cv2.createTrackbar(\"Sat Max\",\"Track Bars\",255,255,empty)\n",
    "cv2.createTrackbar(\"Val Min\",\"Track Bars\",27,255,empty)\n",
    "cv2.createTrackbar(\"Val Max\",\"Track Bars\",255,255,empty)\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "cap.set(10,100)\n",
    "while True:\n",
    "    success,img = cap.read()\n",
    "    cv2.imshow(\"Video\",img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    imghsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "#read and apply track barvalue\n",
    "    h_min = cv2.getTrackbarPos(\"Hue Min\",\"Track Bars\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue Max\",\"Track Bars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat Min\",\"Track Bars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat Max\",\"Track Bars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val Min\",\"Track Bars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val Max\",\"Track Bars\")\n",
    "    \n",
    "    lower = np.array([h_min,s_min,v_min])\n",
    "    upper = np.array([h_max,s_max,v_max])\n",
    "    #mask for applying trackbars on current image nad check effects\n",
    "    mask = cv2.inRange(imghsv,lower,upper)#image,lowerlimit,upperlimit\n",
    "    \n",
    "    imgresult = cv2.bitwise_and(img,img,mask = mask)#bitwise comparision of white part in mask and the pixel in real image and links them\n",
    "\n",
    "    cv2.imshow('org',img)\n",
    "    cv2.imshow('hsv',imghsv)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',imgresult)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contour bordering\n",
    "def getContours(img):\n",
    "    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)#img,retrievalmethod,no.ofcontours\n",
    "    #cv2.RETR_EXTERNAL retrieves extreme outer contours\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        print(area)\n",
    "        if area > 500:\n",
    "            cv2.drawContours(imgcontour,cnt,-1,(255,0,0),3)#img,contour,part selection of image,color,thickness\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            #print(peri)\n",
    "            #finding number of vertices\n",
    "            approx = cv2.approxPolyDP(cnt,0.02*peri,True)\n",
    "            print(len(approx))\n",
    "            #creating boundary around the object\n",
    "            obj = len(approx)\n",
    "            x,y,w,h = cv2.boundingRect(approx)\n",
    "            cv2.rectangle(imgcontour,(x,y),(x+w,y+h),(0,255,0),2)#img,startpoint,diagonal point,color,thickness\n",
    "            #Guessing object name with respective to no. of vertices\n",
    "            if obj == 3:\n",
    "                objtype = \"TRI\"\n",
    "            elif obj == 4:\n",
    "                asprat = w/float(h)\n",
    "                if asprat>0.95 and asprat<1.05:\n",
    "                    objtype = \"Square\"\n",
    "                else:\n",
    "                    objtype = \"Rectangle\"\n",
    "            elif obj == 5:\n",
    "                objtype = \"Pentagon\"\n",
    "            else:\n",
    "                objtype = \"None\"\n",
    "            cv2.putText(imgcontour,objtype,(x+(w//2)-10,y+(h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.5,(0,0,0),2)#img,position,font,scale,color,thickness\n",
    "            \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path = \"C:/Users/H/Documents/shapes.png\"\n",
    "img = cv2.imread(path)\n",
    "imgcontour = img.copy()\n",
    "\n",
    "imggray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "imgblur = cv2.GaussianBlur(imggray,(7,7),1)\n",
    "imgcanny = cv2.Canny(imgblur,60,60)\n",
    "getContours(imgcanny)\n",
    "\n",
    "cv2.imshow(\"Orginal\",img)\n",
    "cv2.imshow(\"gray\",imggray)\n",
    "cv2.imshow(\"blur\",imgblur)\n",
    "cv2.imshow('canny',imgcanny)\n",
    "cv2.imshow('contour',imgcontour)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face recognition\n",
    "import cv2\n",
    "faceCascade = cv2.CascadeClassifier(\"C:/Users/H/Documents/opencv/opencv-master/data/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "img = cv2.imread(\"C:/Users/H/Documents/playlist/sur.png\")\n",
    "imggray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = faceCascade.detectMultiScale(imggray,1.1,2)#img,scale,minneighbours\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,x+h),(255,0,0),2)\n",
    "\n",
    "cv2.imshow(\"titanic\",img)\n",
    "cv2.imshow('gray',imggray)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 color pen drawing on camfeed\n",
    "import cv2\n",
    "import numpy as np\n",
    "width = 900\n",
    "height = 700\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,width)\n",
    "cap.set(4,height)\n",
    "cap.set(10,150)\n",
    "\n",
    "myColors = [[12,135,129,34,255,255],[133,56,0,159,156,255],[5,111,195,29,255,255]]\n",
    "myColorValues = [[0,255,255],[76,0,153],[51,153,255],[0,0,0]]#bgr values not rgb\n",
    "mypoints = []\n",
    "\n",
    "def findColor(img,myColors,myColorValues):\n",
    "    imghsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV) \n",
    "    count = 0\n",
    "    newpoints = []\n",
    "    for color in myColors:\n",
    "        lower = np.array(color[0:3])\n",
    "        upper = np.array(color[3:6])\n",
    "        #mask for applying trackbars on current image nad check effects\n",
    "        mask = cv2.inRange(imghsv,lower,upper)#image,lowerlimit,upperlimit\n",
    "        x,y = getContours(mask)\n",
    "        cv2.circle(imgresult,(x,y),10,myColorValues[count],cv2.FILLED)\n",
    "        if x!=0 and y != 0:\n",
    "            newpoints.append([x,y,count])\n",
    "        count+=1\n",
    "        #cv2.imshow(str(color[0]),mask)\n",
    "    return newpoints\n",
    "\n",
    "def getContours(img):\n",
    "    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)#img,retrievalmethod,no.ofcontours\n",
    "    #cv2.RETR_EXTERNAL retrieves extreme outer contours\n",
    "    x,y,w,h = 0,0,0,0\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 500:\n",
    "            cv2.drawContours(imgresult,cnt,-1,(255,0,0),3)#img,contour,part selection of image,color,thickness\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            #print(peri)\n",
    "            #finding number of vertices\n",
    "            approx = cv2.approxPolyDP(cnt,0.02*peri,True)\n",
    "            x,y,w,h = cv2.boundingRect(approx)\n",
    "    \n",
    "    return x+y//2,y\n",
    "\n",
    "def draw(mypoints,myColorValues):\n",
    "    for point in mypoints:\n",
    "        cv2.circle(imgresult,(point[0],point[1]),10,myColorValues[point[2]],cv2.FILLED)\n",
    "\n",
    "\n",
    "while True:\n",
    "    success,img = cap.read()\n",
    "    imgresult = img.copy()\n",
    "    newpoints = findColor(img,myColors,myColorValues)\n",
    "    if len(newpoints)!=0:\n",
    "        for new in newpoints:\n",
    "            mypoints.append(new)\n",
    "    if len(mypoints)!=0:\n",
    "        draw(mypoints,myColorValues)\n",
    "    cv2.imshow(\"Video\",imgresult)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face and eye detector on eye feed\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = 1000\n",
    "height = 1000\n",
    "cap.set(3,width)\n",
    "cap.set(4,height)\n",
    "cap.set(10,150)\n",
    "\n",
    "\n",
    "face = cv2.CascadeClassifier(\"C:/Users/H/Documents/opencv/opencv-master/data/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "eye = cv2.CascadeClassifier(\"C:/Users/H/Documents/opencv/opencv-master/data/haarcascades/haarcascade_eye.xml\")\n",
    "\n",
    "while True:\n",
    "    success,img = cap.read()\n",
    "    imggray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face.detectMultiScale(imggray,1.3,5)\n",
    "    eyes = eye.detectMultiScale(imggray,1.3,5)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,0),2)\n",
    "        cv2.putText(img,\"FACE\",(x+w+10,y+h+10),cv2.FONT_HERSHEY_COMPLEX,0.5,(200,30,200),2)#img,position,font,scale,color,thickness\n",
    "        roigray = imggray[y:y+h,x:x+w]\n",
    "        roicolor = img[y:y+h,x:x+w]\n",
    "        eyes = eye.detectMultiScale(roigray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roicolor,(ex,ey),(ex+ew,ey+eh),(255,0,0),2)\n",
    "            cv2.putText(img,\"EYE\",(ex+ew+100,ey+eh+100),cv2.FONT_ITALIC,0.5,(20,200,200),2)#img,position,font,scale,color,thickness\n",
    "   \n",
    "    cv2.imshow(\"Video\",img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image similarity finder\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img1 = cv2.imread(\"C:/Users/H/Documents/simpsons.jpg\")\n",
    "img2 = cv2.imread(\"C:/Users/H/Documents/barts.PNG\")\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "kp1,des1 = orb.detectAndCompute(img1,None)\n",
    "kp2,des2 = orb.detectAndCompute(img2,None)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING,crossCheck = True)\n",
    "\n",
    "matches = bf.match(des1,des2)\n",
    "matches = sorted(matches,key = lambda x:x.distance)\n",
    "\n",
    "img3 = cv2.drawMatches(img1,kp1,img2,kp2,matches[:30],None,flags=2)\n",
    "plt.imshow(img3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
